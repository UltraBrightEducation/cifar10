{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image classification with Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the beginning of each project, we import the libraries and required dependencies, as well as configure preferred settings in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix\n",
    "import os\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import glob\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from utils.plotting import plot_confusion_matrix\n",
    "from model.trainer import Cifar10Trainer\n",
    "from data.processing import standardize_data\n",
    "from model.evaluate import evaluate_model\n",
    "from utils.plotting import plot_confusion_matrix, plot_multi_auc\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "The cifar10 dataset contains a total of 50,000 images for training, 10,000 images for testing.\n",
    "\n",
    "Let's load the dataset and take a look at the contents to understand how it is structured.\n",
    "\n",
    "The dataset is already avaiable as part of the Keras dataset library. We can use the method \"cifar10.load_data\" to load the data into an array in memory.\n",
    "\n",
    "We will then inspect the array objects to see the contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "label_list = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "label_decoder = {i: label for i, label in enumerate(label_list)}\n",
    "print(f\"the training dataset image dimensions are: {x_train.shape}\")\n",
    "print(f\"the training dataset label dimensions are: {y_train.shape}\")\n",
    "print(f\"the test dataset image dimensions are: {x_test.shape}\")\n",
    "print(f\"the test dataset label dimensions are: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do the 4 numbers in the training dataset image dimensions mean?\n",
    "\n",
    "What do the 2 numbers in the training data label dimensions mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the image dataset\n",
    "`x_train` and `x_test` represent the training and test images in raw numerical numbers.\n",
    "\n",
    "We see that the `x_train` object has a dimension of (50000, 32, 32, 3)\n",
    "\n",
    "<br>\n",
    "Here's how to interpret these dimensional numbers:\n",
    "\n",
    "The first dimension is 50,000 units in length, this dimension indexes individual image examples\n",
    "\n",
    "The second dimension is 32 units in length, this dimension is the vertical axis of the image\n",
    "\n",
    "The third dimension is 32 units in length, this dimension is the horizontal axis of the image\n",
    "\n",
    "The fourth dimension is 3 units in length, this dimension is the color channel axis of the image\n",
    "\n",
    "<br>\n",
    "`y_train` and `y_test` are the training and test ground truth labels for each of the image examples.\n",
    "\n",
    "Let's take a look at the training image data.\n",
    "We can select the first example, of the first channel (red color) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train[0, ::2, ::2, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "The notation of ::2 means selecting elements in steps of 2 (every other element). If we take every other element in the horizontal and vertical axis, how many numbers in the rows and columns do you expect?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a total of 10 object classes, they are each represented by a digit from 0 to 9.\n",
    "\n",
    "Respectively, they are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = [print(f\"{label}, {value}\") for label, value in label_decoder.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's take a look at how many image examples are there per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_collections = {}\n",
    "for i in range(len(label_decoder)):\n",
    "    indices, _ = np.where(y_train == i)\n",
    "    label_collections[i] = indices\n",
    "    print(f\"number of {label_decoder[i]} examples: {indices.size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision / Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two common metrics to measure the performance of classification models are \n",
    "1. Precison\n",
    "2. Recall\n",
    "\n",
    "Precision is defined as:\n",
    "\n",
    "`number of correct positive predictions / number of predicted positive examples`\n",
    "\n",
    "Recall is defined as:\n",
    "\n",
    "`number of correct positive predictions / number of actual positive examples`\n",
    "\n",
    "\n",
    "Below, we created a mocked up model which predicted the classification of 16 different images. Each image is shown with the actual label, as well as the predicted label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(423)\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "columns = 4\n",
    "rows = 5\n",
    "proba = 0.8\n",
    "true_labels = []\n",
    "preds = []\n",
    "for i in range(1, columns*rows +1):\n",
    "    img_id = np.random.choice(x_train.shape[0])\n",
    "    img = x_train[img_id]\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(img)\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])\n",
    "    true_labels.append(y_train[img_id].item())\n",
    "    if np.random.rand(1) > proba:\n",
    "        preds.append(np.random.choice([x for x in range(10) if x != true_labels[i-1]]))\n",
    "    else:\n",
    "        preds.append(true_labels[i-1])\n",
    "    plt.title(f\"actual: {label_decoder[true_labels[i-1]]} \\n predicted: {label_decoder[preds[i-1]]}\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model produced the predictions above (given the actual label as shown)\n",
    "\n",
    "What is the precision of the model?\n",
    "\n",
    "What is the recall of the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A confusion matrix is a table that is often used to describe the performance of a classification model (or \"classifier\") on a set of test data for which the true values are known. Each row of the matrix represents the instances in a actual class while each column represents the instances in an predicted class.\n",
    "\n",
    "Based on the same mock up model predictions for the 16 images, we can visualize the performance of the model using a confusion matrix. Each row of the confusion matrix table represents the actual class of each of the 16 image examples, while each column of the table represents the predicted class for the same images.\n",
    "\n",
    "For instance, the top row is labeled `airplane`, looking across this row, we see that the number 1 appears in first column (which is Predicte label of `airplane`). This means that of the one image that is actually `airplane`, the model also predicted it to be `airplane`.\n",
    "\n",
    "Let's take a look at the row labeled `bird`. Looking across this row, the number 2 appearing in a column also labeled `bird`. Meaning that 2 images are predicted correctly as `bird`. We also see that a number 1 appears in the predicted column labeled `dog`. This means the single image which is actually `bird` is predicted incorrectly as `dog`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(true_labels, preds, average=\"micro\")\n",
    "print(f\"precision score of the model is {precision}\")\n",
    "plot_confusion_matrix(true_labels, preds, classes=label_list,\n",
    "                      title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the model prediction accuracy for the class `horse`? Accuracy is defined as \n",
    "\n",
    "`the number of correct predictions / total number of images in that class`\n",
    "\n",
    "Which classes of images did the model perform the worst on? i.e., lowest percentage of correct predictions.\n",
    "\n",
    "Which classes of images did the model predicted perfectly on? i.e., all image labels correctly predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RGB Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image in the CIFAR10 dataset is composed of 3 color channels, Red, Green and Blue.\n",
    "\n",
    "Below, we plot the colored image next to each of the channels in grayscale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id_to_view = 24\n",
    "image = x_train[image_id_to_view]\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "plt.grid(b=None)\n",
    "fig.add_subplot(1, 4, 1)\n",
    "plt.imshow(image)\n",
    "plt.grid(b=None)\n",
    "plt.title(\"Colored\")\n",
    "titles = [\"Channel 1\", \"Channel 2\", \"Channel 3\"]\n",
    "channel_mapping = {0:2, 1:1, 2:0}\n",
    "for i in range(3):\n",
    "    fig.add_subplot(1, 4, i + 2)\n",
    "    plt.imshow(image[:,:,channel_mapping[i]], cmap='gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.grid(b=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the color image and the grayscale maps for each channel, can you figure out which Channel is Red, Green and Blue?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Channel 1 is \n",
    "\n",
    "Channel 2 is \n",
    "\n",
    "Channel 3 is "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can modify the `image_id_to_view` above and rerun the cell to see different images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label one-hot-encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `y_train` contains the training dataset ground truth labels. As we have seen previously, it has the following dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"the training dataset label dimensions are: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 50,000 example images, each with a single label, represented by a number from 0 to 9 (for a total of 10 image classes)\n",
    "\n",
    "Let's see the first 10 examples of the labels in the `y_train` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train[:10, 0])\n",
    "print([label_decoder[x] for x in y_train[:10, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each numerical value can be mapped to a text description of the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = [print(f\"{label}, {value}\") for label, value in label_decoder.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These labels constitute the targets which the model will attempt to learn during the training process. Given each input image, the model optimizer will slowly adjust its internal parameters to improve its accuracy in predicting the correct class labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the numerical representation of the class labels, it would seem that this is similar to a regression model, i.e., given an input image, predict a numerical value. However, if we solve this as a regression problem, the model performance will likely be poor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are some reasons that this model will not work well if it is constructed as a regression problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cannot simply ask the model to simply learn to predict a value between 0-9. Instead, since there are 10 classes of images, we can set up the model to predict 10 separate numbers, each representing the likelihood that the image belong to each class.\n",
    "\n",
    "To this end, we use a technique called one-hot encoding where the original values between 0-9 is represented (or encoded) by an array of 10 binary values, each of which can take on a value of either 0 or 1. The position of the element within the array that takes on a value of 1 corresponds to the value of the original class label. Note that for each array, only 1 element can have a value of 1, the rest of the array must be all zeros.\n",
    "\n",
    "For example, a label value of 2 can be represented by the following array:\n",
    "\n",
    "`[0, 0, 1, 0, 0, 0, 0, 0, 0, 0]`\n",
    "\n",
    "The value 1 appears in the 3rd element in the array, therefore, this array represents the value of 2 (counting from 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do you represent the number 5 (out of 10 classes) using one-hot encoding?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a convenient function `to_categorical` which converts numerical representations to one-hot encoded representations.\n",
    "\n",
    "Let's take a look at the 11th to 20th examples in the training dataset in this one-hot encoding form, displayed as a table of values. Each row in this table is one example. The column position of the \"1\" element represents the oiginal numerical value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_one_hot = keras.utils.to_categorical(y_train, num_classes=np.unique(y_train).size)\n",
    "print(y_train_one_hot[10:20,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot this in a color coded chart (called a heatmap)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_plot = y_train_one_hot[10:20,:].astype(int)\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "im = ax.imshow(one_hot_plot, interpolation='nearest', cmap=\"Blues\")\n",
    "ax.grid(False)\n",
    "fmt = 'd'\n",
    "thresh = np.max(one_hot_plot) / 2\n",
    "for i in range(one_hot_plot.shape[0]):\n",
    "    for j in range(one_hot_plot.shape[1]):\n",
    "        ax.text(j, i, format(one_hot_plot[i, j], fmt),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if one_hot_plot[i, j] > thresh else \"black\")\n",
    "ax.set_xticks([x for x in range(len(label_list))])\n",
    "ax.set_yticks([i for i in range(one_hot_plot.shape[0])])\n",
    "fig.tight_layout()\n",
    "plt.xlabel(\"label\")\n",
    "plt.ylabel(\"example\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given these one-hot encoded labels, can you decode the original text descriptions for each of the 10 examples?\n",
    "You can use the following code to display the decoding dictionary\n",
    "\n",
    "`_ = [print(f\"{label}, {value}\") for label, value in label_decoder.items()]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### execute the decoding dictionary here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class labels for the 10 examples are:\n",
    "\n",
    "<br> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the images can be used by the learning algorithm to build a classifier efficiently, there are several preprocessing steps that are typically performed to improve the training process and model results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take the first 100 image examples and collect all the image pixel values. Next, a histogram or distribution plot is created, which shows the distribution (fraction) of pixels that take on each binned value ranges.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = x_train[:500,:,:,0].copy()\n",
    "sns.distplot(test_images.ravel(), bins=50)\n",
    "plt.xlabel('Bin values')\n",
    "plt.ylabel('Fraction of pixels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure above has 50 bins, between 0 and 255, the height of each bar shows the fraction of pixels which fall within the bin range.\n",
    "For example, the first bin has a height of 0.002, meaning that 0.2% of the pixels falls within this range of values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the size (width) of each bin?\n",
    "\n",
    "Which bin is the most common (approximately)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very common preprocessing step in machine learning for continuous input data (numerical values, such as image pixel values) is mean subtraction. This is done in two simple steps.\n",
    "\n",
    "1. Calculate the average (mean) pixel value\n",
    "2. Subtract the average (mean) pixel value from average pixel\n",
    "\n",
    "The effect of this is that the distribution of pixel values will be 'centered' at 0. The reason for doing this is beyond the scope of this exercise, but in a nutshell, this makes it easier for the model optimizer to learn the weights quickly (and reach better results).\n",
    "\n",
    "Below, we perform the mean subtraction step and display the resulting pixel value distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = test_images.astype(float)\n",
    "test_images -= np.mean(test_images)\n",
    "sns.distplot(test_images.ravel(), bins=50)\n",
    "plt.xlabel('Bin values')\n",
    "plt.ylabel('Fraction of pixels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the new distribution, what is the approximate average pixel value in the original data?\n",
    "\n",
    "Did the `shape` of the histogram change?\n",
    "\n",
    "If it changed, why?\n",
    "\n",
    "If it did not change, why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common technique for image preprocessing is called `standardization`. The objective of this step is to transform the data such that the pixel values have a distribution with standard deviation of 1. The process is performed in two steps.\n",
    "\n",
    "1. Mean substraction (already completed in the previous cells)\n",
    "2. Normalize by the standard deviation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we perform the standardization step and display the new distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images /= np.std(test_images)\n",
    "sns.distplot(test_images.ravel(), bins=50)\n",
    "plt.xlabel('Bin values')\n",
    "plt.ylabel('Fraction of pixels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Did the `shape` of the distribution change?\n",
    "\n",
    "What information is lost in the standardization step?\n",
    "\n",
    "Do you think the information lost matter for the purpose of model training?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we perform the one-hot encoding steps and the standardization steps to the actual dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=10)\n",
    "x_train = standardize_data(x_train)\n",
    "x_test = standardize_data(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the input data has been well prepared, we can begin training a convolutional neural network model.\n",
    "\n",
    "Due to the complexity of the model architecture, and the programming involved in defining a network, here we will use a pre-built network and allow you to adjust the parameters that affect the various aspects of the optimization process as well as image augmentation methods.\n",
    "\n",
    "All the tunable parameters are specified using the `hyperparameters` variable. It is a dictionary, indicating the `key` and `value` pairs. The `key` is the name of the parameter, the `value` is the setting for that parameter.\n",
    "\n",
    "Here's a brief explanation of each parameter\n",
    "\n",
    "`learning_rate`: This determines how fast the neural network weights are updated per iteration step, the larger the number, the faster the models learns, however too high a number will result in learning instability and model divergence\n",
    "\n",
    "`batch_normalization`: This is an advanced (but now common-place) normalization technique. In addition to normalizing the input image data, this parameter will tell the algorithm to normalize the output of certain network layers per batch of images calculate. You can set this to False and see what the effects are\n",
    "\n",
    "`weight_decay`: This is a regularization technique which prevents the network weights from getting too large. The effect is that the model is more generalizable and performs better on test dataset when properly tuned. However, when the value is too large, the performance of the model will drop.\n",
    "\n",
    "`base_filters`: base number of convolution filters\n",
    "\n",
    "`batch_size`: number of images to train per iteration\n",
    "\n",
    "`fc_size`: number of nodes per dense neural network layer\n",
    "\n",
    "`dropout`: the probability in which a node output is set to 0, this improves the generalizability of the model and prevents the network from relying heavily in any one node\n",
    "\n",
    "`lr_decay`: exponential decay rate of the learning rate, this helps the model stabilize around the loss minimum, however, if the decay is too large, the model will learn very slowly\n",
    "\n",
    "`rotation_angle`: image augmentation, rotation of the image\n",
    "\n",
    "`width_shift_range`: image augmentation, width shift of the image\n",
    "\n",
    "`height_shift_range`: image augmentation, height shift of the image\n",
    "\n",
    "`shear_range`: image augmentation, range of image shear\n",
    "\n",
    "`zoom_range`: image augmentation, range of image zoom\n",
    "\n",
    "`horizontal_flip`: image augmentation, whether to flip the image horizontally\n",
    "\n",
    "`early_stopping_patience`: how many epochs to wait till the model training is stopped (after the loss ceases to decrease)\n",
    "\n",
    "`reduce_lr_patience`: how many epochs between learning rate reduction\n",
    "\n",
    "`reduce_lr_factor`: reduction factor of the learning rate for every \"reduce_lr_patience\" epochs\n",
    "\n",
    "`activation`: activation function (relu, sigmoid, tanh)\n",
    "\n",
    "`classification_activation`: activation function of the output layer, \"softmax\" for multi-class problems\n",
    "\n",
    "`loss`: loss function, \"categorical_crossentropy\" for multi-class problems which one-hot encoded labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "  \"learning_rate\": 0.001,\n",
    "  \"batch_normalization\": True,\n",
    "  \"weight_decay\": 1e-4,\n",
    "  \"base_filters\": 32,\n",
    "  \"batch_size\": 64,\n",
    "  \"fc_size\": 128,\n",
    "  \"dropout\": 0.2,\n",
    "  \"lr_decay\": 1e-6,\n",
    "  \"rotation_angle\": 15,\n",
    "  \"width_shift_range\": 0.1, \n",
    "  \"height_shift_range\": 0.1,\n",
    "  \"shear_range\": 0.1,\n",
    "  \"zoom_range\": 0.1,\n",
    "  \"horizontal_flip\": True,\n",
    "  \"early_stopping_patience\": 15,\n",
    "  \"reduce_lr_patience\": 6,\n",
    "  \"reduce_lr_factor\": 0.3,\n",
    "  \"activation\": \"relu\",\n",
    "  \"classifier_activation\": \"softmax\",\n",
    "  \"loss\": \"categorical_crossentropy\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the directory and training job names to save artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_base = \"/tmp/artifact/cifar10\"\n",
    "job_name = \"training_job_\"\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "artifact_directory = os.path.join(artifact_base, job_name+timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will create a model trainer object, this will also display the model architecture and output shape of each individual layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Cifar10Trainer(\n",
    "    model_name=\"convnet6\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    artifact_directory=artifact_directory,\n",
    "    x_train=x_train,\n",
    "    y_train=y_train,\n",
    "    x_test=x_test,\n",
    "    y_test=y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many convolution layers are there?\n",
    "\n",
    "How many pooling layers are there?\n",
    "\n",
    "What is the size of the flattened vector which is feeding the final classifier dense_1 neural network?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can initiate the training using the method `train()`\n",
    "\n",
    "The progress of the training will be displayed in epochs. Each epoch is one complete run through the entire training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the model evaluation results for a pre-trained artifact.\n",
    "\n",
    "We will look at the confusion matrix, as well as the Receiver Operating Charateristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_artifact = \"../artifacts/weights.92-0.449348.hdf5\"\n",
    "fpr, tpr, roc_auc, cm = evaluate_model(model_artifact, x_test, y_test, label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the confusion matrix, which class of object did the model have the most trouble with?\n",
    "\n",
    "Which other classes did the model confuse this class with most?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Evaluate your own model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_paths = glob.glob(os.path.join(artifact_directory, \"*.hdf5\"))\n",
    "print('all available model artifacts:')\n",
    "for i, path in enumerate(artifact_paths):\n",
    "    print(f'epoch {i+1} artifact: {path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter the file path for the model artifact you'd like to evaluate below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_artifact = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, roc_auc, cm = evaluate_model(model_artifact, x_test, y_test, label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you tune the model to obtain accuracy > 0.88?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you add one more convolutional layer to the model, right before the flatten layer?\n",
    "\n",
    "Hint: you'll need to modify /cifar10/model/model.py source code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
