{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix\n",
    "import os\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from utils.plotting import plot_confusion_matrix\n",
    "from model.trainer import Cifar10Trainer\n",
    "from data.processing import standardize_data\n",
    "from model.evaluate import evaluate_model\n",
    "from utils.plotting import plot_confusion_matrix, plot_multi_auc\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "label_list = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "label_decoder = {i: label for i, label in enumerate(label_list)}\n",
    "print(f\"the training dataset image dimensions are: {x_train.shape}\")\n",
    "print(f\"the training dataset label dimensions are: {y_train.shape}\")\n",
    "print(label_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_collections = {}\n",
    "for i in range(10):\n",
    "    indices, _ = np.where(y_train == i)\n",
    "    label_collections[i] = indices\n",
    "    print(f\"number of {label_decoder[i]} examples: {indices.size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision / Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "columns = 4\n",
    "rows = 5\n",
    "proba = 0.8\n",
    "true_labels = []\n",
    "preds = []\n",
    "for i in range(1, columns*rows +1):\n",
    "    img_id = np.random.choice(x_train.shape[0])\n",
    "    img = x_train[img_id]\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(img)\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])\n",
    "    true_labels.append(y_train[img_id].item())\n",
    "    if np.random.rand(1) > proba:\n",
    "        preds.append(np.random.choice([x for x in range(10) if x != true_labels[i-1]]))\n",
    "    else:\n",
    "        preds.append(true_labels[i-1])\n",
    "    plt.title(f\"actual: {label_decoder[true_labels[i-1]]} \\n predicted: {label_decoder[preds[i-1]]}\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(true_labels, preds, average=\"micro\")\n",
    "print(f\"precision score of the model is {precision}\")\n",
    "plot_confusion_matrix(true_labels, preds, classes=label_list,\n",
    "                      title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RGB Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = x_train[43]\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "fig.add_subplot(1, 4, 1)\n",
    "plt.imshow(image)\n",
    "plt.title(\"Colored\")\n",
    "titles = [\"R\", \"G\", \"B\"]\n",
    "for i in range(3):\n",
    "    fig.add_subplot(1, 4, i + 2)\n",
    "    plt.imshow(image[:,:,i], cmap='gray')\n",
    "    plt.title(titles[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label one-hot-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train[:10, 0])\n",
    "print([label_decoder[x] for x in y_train[:10, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_one_hot = keras.utils.to_categorical(y_train, num_classes=np.unique(y_train).size)\n",
    "print(y_train_one_hot[:10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_plot = y_train_one_hot[:10,:].astype(int)\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "im = ax.imshow(one_hot_plot, interpolation='nearest', cmap=\"Blues\")\n",
    "fmt = 'd'\n",
    "thresh = np.max(one_hot_plot) / 2\n",
    "for i in range(one_hot_plot.shape[0]):\n",
    "    for j in range(one_hot_plot.shape[1]):\n",
    "        ax.text(j, i, format(one_hot_plot[i, j], fmt),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if one_hot_plot[i, j] > thresh else \"black\")\n",
    "fig.tight_layout()\n",
    "plt.xlabel(\"label\")\n",
    "plt.ylabel(\"example\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original pixel value distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = x_train[:100].copy()\n",
    "sns.distplot(test_images.ravel(), bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = test_images.astype(float)\n",
    "test_images -= np.mean(test_images)\n",
    "sns.distplot(test_images.ravel(), bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images /= np.std(test_images)\n",
    "sns.distplot(test_images.ravel(), bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=10)\n",
    "x_train = standardize_data(x_train)\n",
    "x_test = standardize_data(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "artifact_base = \"/tmp/artifact/cifar10\"\n",
    "\n",
    "hyperparameters = {\n",
    "  \"learning_rate\": 0.001,\n",
    "  \"batch_normalization\": True,\n",
    "  \"weight_decay\": 1e-4,\n",
    "  \"base_filters\": 32,\n",
    "  \"batch_size\": 64,\n",
    "  \"fc_size\": 128,\n",
    "  \"dropout\": 0.2,\n",
    "  \"lr_decay\": 1e-6,\n",
    "  \"rotation_angle\": 15,\n",
    "  \"width_shift_range\": 0.1, \n",
    "  \"height_shift_range\": 0.1,\n",
    "  \"shear_range\": 0.1,\n",
    "  \"zoom_range\": 0.1,\n",
    "  \"horizontal_flip\": True,\n",
    "  \"early_stopping_patience\": 15,\n",
    "  \"reduce_lr_patience\": 6,\n",
    "  \"reduce_lr_factor\": 0.3,\n",
    "  \"activation\": \"relu\",\n",
    "  \"classifier_activation\": \"softmax\",\n",
    "  \"loss\": \"categorical_crossentropy\"\n",
    "}\n",
    "job_name = \"training_test_\"\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "artifact_directory = os.path.join(artifact_base, job_name+timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Cifar10Trainer(\n",
    "    model_name=\"convnet6\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    artifact_directory=artifact_directory,\n",
    "    x_train=x_train,\n",
    "    y_train=y_train,\n",
    "    x_test=x_test,\n",
    "    y_test=y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_artifact = \"../artifacts/weights.92-0.449348.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, roc_auc, cm = evaluate_model(model_artifact, x_test, y_test, label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
